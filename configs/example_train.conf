[1]
label = conll04_train
model_path = /home/Pretrain-Model/bert-base-cased
tokenizer_path = /home/Pretrain-Model/bert-base-cased
train_path = data/datasets/conll04/conll04_train.json
valid_path = data/datasets/conll04/conll04_dev.json
types_path = data/datasets/conll04/conll04_types.json
train_batch_size = 1
eval_batch_size = 1
cuda_id = cuda:0
encoder_layers = 2
encoder_heads = 8
dropout = 0.1
neg_entity_count = 80
neg_relation_count = 80
max_span_size = 10
lr = 1e-5
epochs = 100
lr_warmup = 0.1
weight_decay = 0.01
max_grad_norm = 1.0
rel_filter_threshold = 0.8
size_embedding = 128
store_examples = true
sampling_processes = 0
sampling_limit = 100
max_pairs = 200
final_eval = true
log_path = data/log/
save_path = data/save/